{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1e2601-7424-447d-89de-be2be00ae309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "\n",
    "from utils import *\n",
    "from dataset import *\n",
    "from encoder import Encoder\n",
    "from decoder import DecodeNext, Decoder\n",
    "from predictor import Predictor\n",
    "\n",
    "from rdkit.Chem import MolFromSmiles, MolToSmiles\n",
    "\n",
    "from IPython.display import Image\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c8f27-399e-4446-a8e5-d6e00a92392c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATADIR = './data/gdb13/'\n",
    "OUTDIR = './run11/'\n",
    "DATASPEC_FILE = os.path.join(DATADIR, 'spec.json')\n",
    "\n",
    "dataspec = fetch_params(DATASPEC_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c97b9-870d-4ad0-9244-dbe71fdbadfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "L = 128\n",
    "\n",
    "if 'run9' in OUTDIR:\n",
    "    encoder = torch.load(OUTDIR + 'encoder.pth')\n",
    "    decoder = torch.load(OUTDIR + 'decoder.pth')\n",
    "    decoder.smile_len = dataspec.smile_len\n",
    "    decoder.alphabet = dataspec.alphabet\n",
    "    decoder.stoi = dataspec.stoi\n",
    "    predictor = torch.load(OUTDIR + 'predictor.pth')\n",
    "else:\n",
    "    encoder = Encoder(L, dataspec)\n",
    "    encoder.load_state_dict(torch.load(OUTDIR + 'encoder_weights.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "    decoder = Decoder(L, dataspec)\n",
    "    decoder.load_state_dict(torch.load(OUTDIR + 'decoder_weights.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "    predictor = Predictor(L)\n",
    "    predictor.load_state_dict(torch.load(OUTDIR + 'predictor_weights.pth', map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe99441-478a-49f9-83ba-8e9104d41585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainset, testset = make_data('./data/gdb13', n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea34a7-8909-4ee0-9e92-c36102a4665c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "means, stds = get_latent_distributions(encoder, testset.hots, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f4bcb8-d190-498f-b5a2-d7fdcf244276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Variant Dimensions: ', [i for i, std in enumerate(stds) if std > 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a673669-3175-4ef8-a2f2-3b3730c896aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CE_LOSS = lambda x, x_hat: float(torch.nn.functional.cross_entropy(x_hat.transpose(1, 2), torch.argmax(x, dim=2)))\n",
    "\n",
    "n = 100\n",
    "\n",
    "sample = trainset.sample(n)\n",
    "\n",
    "losses = [0] * L \n",
    "\n",
    "for i, x in enumerate(sample):\n",
    "    x = x.unsqueeze(0)\n",
    "    \n",
    "    mu, _, _ = encoder(x)\n",
    "\n",
    "    reference_loss = CE_LOSS(x, decoder(mu))\n",
    "\n",
    "    for i in range(L):\n",
    "        weight = float(mu[:, i])\n",
    "        mu[:, i] = 0\n",
    "        losses[i] += CE_LOSS(x, decoder(mu)) - reference_loss\n",
    "        mu[:, i] = weight\n",
    "\n",
    "losses = [loss/n for loss in losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f803b-314e-4cf1-8d7c-d3a18c7b094a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Sensitive Dimensions: ', [i for i, loss in enumerate(losses) if loss > 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ab2d68-e173-4fad-9f05-c740102f93a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(range(L), losses)\n",
    "ax.set_xlabel('dimension number')\n",
    "ax.set_ylabel('loss difference')\n",
    "ax.set_title('change in decoder loss from zeroing each latent dimension (run9, 100 samples)')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6e507-2b49-40af-99cb-1d72db638682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smiles = set()\n",
    "invalid = 0\n",
    "\n",
    "n = 1000\n",
    "\n",
    "for i in range(n):\n",
    "    z = torch.normal(means, stds).unsqueeze(0)\n",
    "    x_hat = decoder(z)\n",
    "    smile = from_hot(x_hat, dataspec.alphabet)[0].replace('L', 'Cl')\n",
    "    \n",
    "    mol = MolFromSmiles(smile)\n",
    "    \n",
    "    if mol:\n",
    "        smile = MolToSmiles(mol)\n",
    "        smiles.add(smile)\n",
    "    else:\n",
    "        invalid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d7f03-d644-44ce-a249-b913c3e0ec80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Diversity:\\t', len(smiles)/(n - invalid))\n",
    "print('Percent Valid:\\t', 1 - invalid/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2cf7d4-d546-4811-be48-e6f825988b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.eval()\n",
    "\n",
    "z, _, _ = encoder(testset.hots[1:2])\n",
    "\n",
    "z = z.squeeze()\n",
    "\n",
    "dim = 124\n",
    "\n",
    "#interval = torch.randn(1000) * stds[dim] + means[dim]\n",
    "\n",
    "logps = []\n",
    "qeds = []\n",
    "sass = []\n",
    "\n",
    "mean = float(means[dim])\n",
    "std = float(stds[dim])\n",
    "\n",
    "interval = torch.arange(start=mean-3*std, end=mean+3*std, step=2*std/1000)\n",
    "\n",
    "for d in interval:\n",
    "    z[dim] = d\n",
    "    logp, qed, sas = predictor(z.unsqueeze(0))\n",
    "    logps.append(float(logp))\n",
    "    qeds.append(float(qed))\n",
    "    sass.append(float(sas))\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(3, 1, sharex=True)\n",
    "ax0.plot(interval, logps)\n",
    "ax1.plot(interval, qeds)\n",
    "ax2.plot(interval, sass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493e081-8d47-4c46-ae5e-bb99577526ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
